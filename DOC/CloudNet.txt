Distributed Architecture


Setup with 2 instances on a LAN:

The internet gateway is configured to forward certain ports to a fixed ip.
Running two instances on a LAN then will have only one of them respond to
packets for the IP. The IP is (pre)configured in the os.

Initialisation routine on a LAN then involves pinging the fixed IP to
determine whether it is available. If so, the NIC is configured with the IP.
If not, another IP is chosen.

The machine that is not using the gateway's forward IP regularly pings the IP,
and when there is no response, reconfigures itself with the IP.

'Master/Slave'

In this setup, only one instance on the lan has the ip, and is called the
'master'. It may be aware of other instances using some protocol, and could
forward packets to load balance within a LAN.

[the above is a todo, there is no checks as yet to count the LAN instances]



WAN: .cloud

subdomain: cloud.neonics.com
subdomain DNS: cloudns.neonics.com (DYNA record).

The OS currently implements a DNS proxy for cloud.neonics.com,
returning the address for cloudns.neonics.com, which is the public ip
of the (so far) only instance running the OS.

The model can serve other domains aswell, and illustrates how updates
can propagate.

All cloud machines will check the main DNS server and register themselves
by using the DNS update mechanism. 




Deployment
----------

It is envisioned that QuRe will be deployed on private (non-corporate)
sites, using modems connected through fiber, the telephone network,
or the media network. The targeted domain then consists of consumers,
which may not have the expertise of advanced network configuration,
or running a server. The gateway then must be assumed to be the most
limiting version. Normally these have a built-in DHCP server.
It is required that these gateways offer portforwarding or DMZ.

There is a number of protocols for dynamic gateway configuration such as
portforwarding, though this is not commonly supported with low-end modems.



Communication behind a gateway (LAN)
------------------------------------
Since a single gateay only can forward packets for a particular port to one IP,
when multiple cloud machines are present behind the gateway, one must be chosen
to handle the requests.

There are a number of options for a protocol that allows the machines to
be aware of each other.
First, some sort of broadcast is necessary:
- the broadcast IP for the subnet
- multicast (224.0.0.0/4)

Second, a protocol is needed:
- multicast group membership: IGMP
- netbios
- DNS

A particular multiast group number can be reserved for cloud based services,
where membership of the group, made known by group reports, indicates
the presence of cloud machines.

Netbios is proprietary and shall not be used.

DNS can be used over multicast.
SSDP is HTTP over multicast.

For IPv6, there is NDP (neighbour discovery protocol), which is ICMPv6,
used for:
- router sollicitation/advertisement
- neighbour sollicitation/advertisement
- redirect


Router Configuration
--------------------
Option 1: fixed IP in LAN subnet outside of DHCP IP range.
Downside: there is no way for the machine to discover which IP this might be,
and thus would be a preconfigured default which would require configuration
in the virtual machine (not zeroconf).

Option 2: fixed multicast IP in some unused range.
Downside: the network will be flooded with all incoming communication. This
is desirable so that it reaches all machines, however, this would nullify
switch optimization which would reduce network traffic once the machine IP's
MAC is known. In most cases however, a router will have WiFi and thus will
broadcast anyway.



Basic operation behind a firewall/gateway
-----------------------------------------
Assumptions:
- All machines know the IP to which the service ports are forwarded;
- All machines are aware of each other through the LAN awareness protcol
- One machine is elected to handle requests, which is known by all machines.

Then, all machines monitor the requests, and can take action when the response
is not forthcoming within a timeout period.

It is foreseen that the machines may be shut down at any time, by
terminating or suspending the virtual machine emulator, in which case they
do not broadcast their disappearance.

Further, response times must be as low as possible, say within a second.

This then would require all machines to communicate their presence with each
other, which would flood the network unnecessarily.

When all machines receive all requests, monitoring the presence of a response
from the elected machine then determines whether or not a new machine must
be elected to handle the response.
D
When a machine detects a timeout in the response time, it can query the
elected machine to see if it is still present. If not, this then serves as
the trigger to elect a new machine to handle requests.


Load balancing
--------------
Multiple machines may handle requests on a socket (remote ip+port) bases
so that requests coming from the same client will be handled by the same
service. Unfortunately the use of HTTP is widespread, which uses many
different connections for a single session, and thus uses different ports.
Furthermore, some remote IP's are gateways themselves, such as in use
by universities, which may house many thousands of clients, all appearing
as the same IP.

---------------------------------------------------------------------

ACPI shutdown detect
--------------------
On shutdown detect, a message can be broadcast.

Shared DMZ
----------
Each vm can implement multiple virtual devices. It can use 192.168.1.11
as the shared DMZ along a DHCP address.
A second MAC must be made - possibly a virtual NIC, for the 2nd IP
address. (like eth0:0).

Running multiple VM's: keep each other informed of who is handling DMZ.
Regular peer-to-peer messages to keep aware of DMZ IP assigned to VM.
On detection of the DMZ vm having gone offline, another takes over.

Host Daemon VM Manager
----------------------
A host daemon can participate in the protocol. It can then configure
all VM's using network messages.
It can also start new VM's and recycle existing ones that do not respond.

VMs can be started in 'nogui' mode (vmrun -T player start file.vmx [no]gui).


Virtual / Shared IP
-------------------
The DMZ ip will be configured as a virtual service ip.

Each cluster node will be configured over the network to support
the DMZ ip.  [at first a single IP, will be made a list later]


Bootstrap Node
---------------
Only a single node needs to be configured, if the other cluster
nodes accept their configuration over the network.


Multicast
---------
All nodes join a group using a GMP (IGMP). This makes use of
multicasting (not broadcasting). To determine which number
represents the cluster communication point, a hardcoded/reserved
number can be used. There can perhaps be a broadcast to request
which groups there are. Perhaps the group can be resolved
using multicast DNS.


DHCP
----
Each node can function as a DHCP server, using a custom service number.
It can return the required network configuration, and some field
can be used to indicate that this is information for the cluster.
In this way, each cluster node can do DHCP requests and receive
multiple answers. One will be the localnet, the other will be
the cluster - such as some identifier (the IP need not be used as such),
and the gateway or server ip fields can indicate which cluster node
is taken to be the cofniguration node.


ZeroConfig Bootstrapping using IP monitoring
--------------------------------------------
The DMZ ip, once configured in the router, will give rise
to public traffic. This traffic will be directed to the DMZ
ip, which the router will ARP.

If there are repeated ARP requests for a certain ID, a node will
answer, claiming the IP, and generating a new MAC different
from it's LAN MAC by which the router knows it. This prevents
caching a temporary MAC with a fixed IP.

In this scheme, the IP is fixed, as it is a service IP configured
in the router. The MAC is temporary, since any cluster node
can take the IP if there is no answer.

A script-expressoin rule for this then might be:

	auto-answer ARP $LANMASK

which would have any node response (sensibly, as it knows the IP
it takes is a shared virtual IP and thus may be in use).

[Best would be to have the router/gateway provide the service IP
in DHCP].


mDNS
----
A fixed addressing scheme - say '.cloud' or '.localcluster' 
can provide SRV records.

The DNS then can serve as a simplified LDAP system, where information
is stored in nodes - an object hierarchy.


Custom Protocol
===============
Requirements:

1) Maintain Cluster Knowledge
-----------------------------
a) broadcast on boot [COMPLETE]
b) multicast PING

	Multicast (notes from cisco)
	---------
	free IP range: 239.0.0.0-239.255.255.255 (239/8)
	(prohibited on internet/ttl=1)
	dynamic allocation:
		SDR, Multicast Address Set Claim (MASC), SSM; MADCAP, SSM 
	
	static: 'GLOP': 233/8: 233.[16bit ASN].[0-255]

	ASN: autonomous system (ISP, content provider).

	SDR - session directory:
	SAP: session announcement protocol
	SDR: well known global mcast say 224.2.127.254.
		IP multicast addresses
		time session

c) cluster uptime: session duration.

Shared Objects
--------------
The goal of the Cluster is to keep all data alive. The cluster
uptime then consists of time since the first node booted.
Taking an OO approach, the cluster maintains objects. 
The root object itself is the cluster uptime and version.
Each time a cluster dies, all of the nodes have powered off.

Each cluster keeps persistent track of boot times.
Cluster nodes might be identifiable by a unique cluster id; their DHCP
IP will generally change.
A history then, a graph of the number of online nodes, is attempted
to be shared and thus kept consistent.

The cluster history consists of events. The events are numbered.
History is divided in ages - each age represents the lifetime of
a cluster. An age then indicates when the first node of a cluster
boots. 
This information is already available, as the DMZ ip - a shared resource -
is requested, and claimed. A second node will (ARP) request the same IP,
but find a response. The first node then knows it was the first,
the second that it wasn't. Each time a node boots that is the first,
it increments the cluster age.

Within an age, the appearance of a node constitutes an event.

Each node broadcasting it's presence will be answered by a single
node. All nodes receive the broad/multi cast. The nodes have chosen
a function - first responder - and determined which node serves
the role. 

When a node appears that announces a prior age than is current,
it receives the history since.

FIRST IMPLEMENTATION
--------------------
hello protocol: send last age ('date').
OOFS: ?/cluster

receives response. If age received:
	less: the cluster is out of date. The nodes haven't been
		participating in the cluster for a while. This
		node then has more recent information, which
		it shares with the rest to update their history
		events.
	more: the reverse.
Note tha tit doesnt matter which node sends or receives - in the broadcast,
the packet is handled as a response by the receiving nodes, who
have chosen one to respond to the booted node. This node will send
the cluster age and it's own.

Nodes then keep track of participating in ages - their personal history.

cluster_history:
	cluster_age:	.long		# array length
	incarnations:	.space 4*?	# [array of cluster_incarnation]

node_history:
	node_age:	.long		# array length
	eras:		.space 4*	# era ID's in which incarnated.

		An era does not change during any node incarnation,
		because a new era only begins if this one ends,
		which is when there are no nodes incarnated.

hello_packet:
	era:	.long 0	# cluster age
	age:	.long 0	# node incarnation





Kernel Revision
---------------
Revisions can be counted per branch using git log --pretty=oneline | wc -l.
The cluster era then can be set to start at a particular revision.
The number of reboots during an era then serves as a second revision
number.
From eras prior to the runtime revision counting their reboots yields
an age: the number of tests, and their duration - history: time between
reboots.

cluster_node_onload:
	mov	edx, [eax + era]
	cmp	edx, KERNEL_REVISION
	jz	1f
	mov	[eax + era], KERNEL_REVISION
	.if ?
	mov	edx, [eax + age]
	mov	[eax + era_start], edx
	.else
	mov	[eax + age], dword ptr 0
	.endif

1:	ret


cluster_get_kernel_version:
	mov	edx, [eax + age]
	sub	edx, [eax + era_start]
	mov	eax, [eax + age]
	ret
