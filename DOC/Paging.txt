Paging

Essentially, paging allows to create an arbitrary mapping between linear
or virtual addresses, and physical addresses. An address is a reference
to something on the bus, such as memory or I/O (memory mapped IO).

This mapping can be used to limit the accessible memory, by having a
smaller usable linear address space than is physically available.

Conversely, paging allows to have a virtual address space that is larger than
the physical memory available. This means that these addresses can be used to
point to something other than memory, such as permanent storage, which can then
be transparently loaded and stored.

Obviously for a linear address to be used it will have to be mapped to
physical memory. Assuming the entire physical memory is mapped, there will
then be duplicate mappings - two or more linear addresses referring to the
same physical memory.

Swapping

Assuming the starting condition that a single region of physical memory
is accessible using two virtual addresses, giving different meaning to 
these addresses can be done by disabling the one that is not currently
accessed. This is possible since the linear address can be obtained in
page fault exceptions in the CR2 register.

Other Uses

* Reserved Linear Addresses

virtual consoles may write to the same linear address, which is either
mapped to video memory or not, depending on whether the console is active.

* Unique address Space

It is possible to offer each process/task its own view of physical memory.
This allows to decide exactly what is visible for any given process. A mapping
can be constructed for each process that makes it appear it is the only process.

Since the paging architecture is hierarchical, there are several levels on
which this can be accomplished. At the top level, the pointer to the paging
directory may be changed for each process. The downside is that this results
in an invalid cache, where the processor will need to access physical memory
to retrieve the needed parts of the paging structure in order to translate
memory references, both for instructions and data. This cache is commonly
called a 'translation-lookaside-buffer' or TLB.

As of this writing, modern processors only support about the same amount
of TLB entries as its number of visible registers. Common is about 8 to 12
registers for 4kb pages, and another 8 or so for 4MB pages. This means
that the range of memory that can be referenced without cache misses
is about 32MB, relatively small compared to the current physical limitations
of several TB.

The overhead of switching the entire paging structure, and thus invalidating
the cache, is said to be from 10 to 100 clock cycles per cacheable page.
Using 4MB pages, only a handful of these at most will be needed, about half
of the TLB size.
Using 4kb pages, likely the cache will be reduced to two code pages (in the
case of code that loops across a page boundary), one or two stack pages,
and three data pages (one static, two heap). It is said the cache is reduced,
as obviously there will be code references to shared libraries in different
pages, and even methods within the same code segment will generally be further
than a page (4kb) apart. Software generally is hierarchical, and uses layers
of abstraction, where each layer's code is generally organized together.
Thus, an API call through three layers of logical abstraction will likely
cause three page faults. Further, only a handful of methods are generally
in the same page, even within a single layer of abstraction, and thus
the envisioned single TLB entry responsible for caching the address translations
required to satisfy the abstraction is seen to change, whereby it's use as
cache is nullified.
Using 4MB pages, the same amount of TLB entries is likely to be used, however,
the page fault interval is larger, first because stack use is generally
within 4Mb and thus won't cross page boundary. Second, because code will not
generally cross page boundaries on loops. Further, abstraction layers
will generally fit within one page.

As such, it appears that even when the paging structure is not modified on
a context switch, it is highly likely that the TLB will need to be replaced
regardless. Each context switch represents a switch to a different application,
using its own architecture and possibly it's own libraries with its own
abstractions.

In a virtual execution environment there will be VMX exits on many occasions,
such as I/O or screen updates. On such a context switch the cache is also
invalidated entirely.

The main purpose for cache invalidation is the different semantics for
identical linear addresses. Operating systems that compile their code to
use a common address, such as 0x00401000, will need to invalidate the TLB
on any context switch between processes. Only when switching between threads
within the same process can this be prevented.

An operating system may improve on TLB performance by locating tasks at
different linear addresses. 

UPDATE: the number of TLB cache entries for code or data of the current machine
(an octa-core (quad core with hyperthreading)) is several 64 or 128.
In this case it would have a serious impact to reset CR3 on a task switch.

----
UPDATE: the cr3 switch is implemented, but no difference is noticable,
likely because a VM switch occurs on each interrupt anyway.
----------------------------------------------------------------------


MEMORY:

The top 4Mb is used for the kernel page directory and page tables,
aswell as for the page tables of tasks.

It is needful to be able to add page tables (PTs) to a tasks page dir (PD).

At current, for tasks, only 2 PDE's are used: the first, for low 4 Mb (kernel space),
and the last one, containing the pages (at current only used as page tables).

A task may not modify the page directory itself. (it's page table is identity-mapped read-only).
A task may not modify the page table for low-mem. (it's page table is identity-mapped read-only).
A task may modify the page table for it's high-mem window.
This means that it's access to all memory must occur through this window.
It is not a restriction to memory access, but to where it is accessible.

We will consider tasks running in CPL 1 or lower, which may not modify CR3 itself,
but may be given write-access to some page tables.

Assuming that none of its page tables are writable, it can still read the page dir,
and the low mem page table.
It cannot map new pages, because the PD is read-only, so no new logical memory  range
can be enabled, and it cannot add a PDE pointing to memory it can write.

malloc_page_phys can be called, but the page cannot be idmapped except when a PTE is
writable.

APPROACH: CPL1 limited segment selectors & writable page tables.

In the case of CPL1, a segment selector can be provided that does not include the
paging table window.
To idmap then, CPL0 must be entered. Now, using the kernel selectors, page tables
can be modified, without switching out CR3.


APPROACH: do not map page tables at all (but do map low-mem).

This means that tasks will not be able to map pages by themselves.
A kernel call can be made, and the page will be idmapped in the page tables
of the task - which are invisible to it, as it's PD is not mapped.

It is not required that the PD be mapped, except for instruction-level access.
The same applies to PT's.
The processor internally does have access, whether or not the page tables are mapped.

KEYBOARD
--------
The keyboard interrupt handler schedules a task.
1) this produces some overhead		- this allows for testing
2) the ISR can occur in any context.

Ad 2. This means that, when the scheduler is running a task and the interrupt occurs,
that CR3 will point to an inaccessible page directory.
As such, schedule_task as called by the ISR cannot map new pages.

ELEVATION
---------
schedule_task already runs in CPL0. However, CR3 is not updated.

paging_idmap* may switch out CR3 in order to:
1) have access to the page itself, for clearing and use as page table
2) have access to the PD and PT of the calling task, to map the page.


